{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indian Express Credit Cards Limited: COVID Impact on Credit Card Defaulters\n",
    "\n",
    "## Problem Statement\n",
    "\n",
    " In this case study, we are going to build a classifier to calculate the probability of a customer defaulting on the credit card.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "credit-default.csv\n",
    "\n",
    "\n",
    "# Dataset Description:\n",
    "\n",
    "Each row is about a customer.W have details about their savings, employment, age, marital status, default column (target column), we have value 1, if the customer has not defaulted and the customer has defaulted with value 2.\n",
    "\n",
    "\n",
    "# Guidelines\n",
    "\n",
    "1.\tIn the target column, replace 1 with 0 and 2 with 1.\n",
    "\n",
    "2.\tSummarize the dataset using various summarization techniques \n",
    "\n",
    "3.\tIdentify whether the target column is balanced or imbalanced. Plot the same using a simp \n",
    "\n",
    "4.\tPerform exploratory data analysis to identify the factors that ifluences customers who are defaulting with bank.\n",
    "\n",
    "5.\tConvert all categorical columns to numerical columns using one hot encoding (i.e. using variables technique) \n",
    "\n",
    "6.\tDivide the dataset in to training (80%) and testing (20%). (Use random_state=1) \n",
    "\n",
    "7.\tStandardize the input variables and use the same wherever required \n",
    "\n",
    "8.\tUse the following algorithms to build a classifier \n",
    "\n",
    " - Logistic regression\n",
    "\n",
    " - Decision Trees\n",
    " \n",
    " - KNN\n",
    "\n",
    " - SVM\n",
    " \n",
    " - Random Forest\n",
    "\n",
    "9.\tWherever required, use trial and error method to identify optimal values for input param depth in decision trees, no. of neighbors in KNN etc) \n",
    "\n",
    "10.\tUsing all the models Predict the target class for test dataset and populate the followin report the same in a consolidated table \n",
    "   - Accuracy \n",
    "\n",
    "   - Sensitivity \n",
    "\n",
    "   - Specificity \n",
    "\n",
    "   - F1-score \n",
    "\n",
    "   - AUC \n",
    "   \n",
    "   - Recall\n",
    "   \n",
    "   - Precision\n",
    "\n",
    "11.\tPlot the ROC curves for all the models in a single plot\n",
    "\n",
    "12.\tJustify your choice of classifier \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, auc, roc_curve \n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>checking_balance</th>\n",
       "      <th>months_loan_duration</th>\n",
       "      <th>credit_history</th>\n",
       "      <th>purpose</th>\n",
       "      <th>amount</th>\n",
       "      <th>savings_balance</th>\n",
       "      <th>employment_length</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>personal_status</th>\n",
       "      <th>other_debtors</th>\n",
       "      <th>...</th>\n",
       "      <th>property</th>\n",
       "      <th>age</th>\n",
       "      <th>installment_plan</th>\n",
       "      <th>housing</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>default</th>\n",
       "      <th>dependents</th>\n",
       "      <th>telephone</th>\n",
       "      <th>foreign_worker</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>6</td>\n",
       "      <td>critical</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>1169</td>\n",
       "      <td>unknown</td>\n",
       "      <td>&gt; 7 yrs</td>\n",
       "      <td>4</td>\n",
       "      <td>single male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>67</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>skilled employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1 - 200 DM</td>\n",
       "      <td>48</td>\n",
       "      <td>repaid</td>\n",
       "      <td>radio/tv</td>\n",
       "      <td>5951</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>1 - 4 yrs</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>22</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>skilled employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>unknown</td>\n",
       "      <td>12</td>\n",
       "      <td>critical</td>\n",
       "      <td>education</td>\n",
       "      <td>2096</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "      <td>2</td>\n",
       "      <td>single male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>real estate</td>\n",
       "      <td>49</td>\n",
       "      <td>none</td>\n",
       "      <td>own</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>unskilled resident</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>42</td>\n",
       "      <td>repaid</td>\n",
       "      <td>furniture</td>\n",
       "      <td>7882</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>4 - 7 yrs</td>\n",
       "      <td>2</td>\n",
       "      <td>single male</td>\n",
       "      <td>guarantor</td>\n",
       "      <td>...</td>\n",
       "      <td>building society savings</td>\n",
       "      <td>45</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>skilled employee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt; 0 DM</td>\n",
       "      <td>24</td>\n",
       "      <td>delayed</td>\n",
       "      <td>car (new)</td>\n",
       "      <td>4870</td>\n",
       "      <td>&lt; 100 DM</td>\n",
       "      <td>1 - 4 yrs</td>\n",
       "      <td>3</td>\n",
       "      <td>single male</td>\n",
       "      <td>none</td>\n",
       "      <td>...</td>\n",
       "      <td>unknown/none</td>\n",
       "      <td>53</td>\n",
       "      <td>none</td>\n",
       "      <td>for free</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>none</td>\n",
       "      <td>yes</td>\n",
       "      <td>skilled employee</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  checking_balance  months_loan_duration credit_history    purpose  amount  \\\n",
       "0           < 0 DM                     6       critical   radio/tv    1169   \n",
       "1       1 - 200 DM                    48         repaid   radio/tv    5951   \n",
       "2          unknown                    12       critical  education    2096   \n",
       "3           < 0 DM                    42         repaid  furniture    7882   \n",
       "4           < 0 DM                    24        delayed  car (new)    4870   \n",
       "\n",
       "  savings_balance employment_length  installment_rate personal_status  \\\n",
       "0         unknown           > 7 yrs                 4     single male   \n",
       "1        < 100 DM         1 - 4 yrs                 2          female   \n",
       "2        < 100 DM         4 - 7 yrs                 2     single male   \n",
       "3        < 100 DM         4 - 7 yrs                 2     single male   \n",
       "4        < 100 DM         1 - 4 yrs                 3     single male   \n",
       "\n",
       "  other_debtors  ...                  property age  installment_plan  \\\n",
       "0          none  ...               real estate  67              none   \n",
       "1          none  ...               real estate  22              none   \n",
       "2          none  ...               real estate  49              none   \n",
       "3     guarantor  ...  building society savings  45              none   \n",
       "4          none  ...              unknown/none  53              none   \n",
       "\n",
       "    housing existing_credits  default  dependents  telephone foreign_worker  \\\n",
       "0       own                2        1           1        yes            yes   \n",
       "1       own                1        2           1       none            yes   \n",
       "2       own                1        1           2       none            yes   \n",
       "3  for free                1        1           2       none            yes   \n",
       "4  for free                2        2           2       none            yes   \n",
       "\n",
       "                  job  \n",
       "0    skilled employee  \n",
       "1    skilled employee  \n",
       "2  unskilled resident  \n",
       "3    skilled employee  \n",
       "4    skilled employee  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load and preview the Store dataset\n",
    "credit = pd.read_csv('C:/Users/ejhajee/Downloads/Case Study Resources-20201127/credit-default.csv')\n",
    "credit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "## Replace values in target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. In the target column, replace 1 with 0 and 2 with 1. So that the defaulters will become \n",
    "#credit['default'] = credit['default'].replace({1:0, 2:1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Summarize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_loan_duration</th>\n",
       "      <th>amount</th>\n",
       "      <th>installment_rate</th>\n",
       "      <th>residence_history</th>\n",
       "      <th>age</th>\n",
       "      <th>existing_credits</th>\n",
       "      <th>default</th>\n",
       "      <th>dependents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>20.903000</td>\n",
       "      <td>3271.258000</td>\n",
       "      <td>2.973000</td>\n",
       "      <td>2.845000</td>\n",
       "      <td>35.546000</td>\n",
       "      <td>1.407000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.155000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>12.058814</td>\n",
       "      <td>2822.736876</td>\n",
       "      <td>1.118715</td>\n",
       "      <td>1.103718</td>\n",
       "      <td>11.375469</td>\n",
       "      <td>0.577654</td>\n",
       "      <td>0.458487</td>\n",
       "      <td>0.362086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1365.500000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>2319.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>3972.250000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>72.000000</td>\n",
       "      <td>18424.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       months_loan_duration        amount  installment_rate  \\\n",
       "count           1000.000000   1000.000000       1000.000000   \n",
       "mean              20.903000   3271.258000          2.973000   \n",
       "std               12.058814   2822.736876          1.118715   \n",
       "min                4.000000    250.000000          1.000000   \n",
       "25%               12.000000   1365.500000          2.000000   \n",
       "50%               18.000000   2319.500000          3.000000   \n",
       "75%               24.000000   3972.250000          4.000000   \n",
       "max               72.000000  18424.000000          4.000000   \n",
       "\n",
       "       residence_history          age  existing_credits      default  \\\n",
       "count        1000.000000  1000.000000       1000.000000  1000.000000   \n",
       "mean            2.845000    35.546000          1.407000     1.300000   \n",
       "std             1.103718    11.375469          0.577654     0.458487   \n",
       "min             1.000000    19.000000          1.000000     1.000000   \n",
       "25%             2.000000    27.000000          1.000000     1.000000   \n",
       "50%             3.000000    33.000000          1.000000     1.000000   \n",
       "75%             4.000000    42.000000          2.000000     2.000000   \n",
       "max             4.000000    75.000000          4.000000     2.000000   \n",
       "\n",
       "        dependents  \n",
       "count  1000.000000  \n",
       "mean      1.155000  \n",
       "std       0.362086  \n",
       "min       1.000000  \n",
       "25%       1.000000  \n",
       "50%       1.000000  \n",
       "75%       1.000000  \n",
       "max       2.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. Summarize the dataset using various summarization techniques \n",
    "credit.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 21)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape of data\n",
    "credit.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Dictionary\n",
    " - Variables - 21\n",
    " - Observations - 1000\n",
    " \n",
    "## Integer Variables:\n",
    " - months_loan_duration\n",
    " - amount\n",
    " - installment_rate\n",
    " - residence_history\n",
    " - age\n",
    " - existing_credits\n",
    " - default\n",
    " - dependents\n",
    " \n",
    "## Categorical Variables:\n",
    " - checking_balance\n",
    " - credit_history\n",
    " - purpose\n",
    " - savings_balance\n",
    " - employment_length\n",
    " - personal_status\n",
    " - other_debtors\n",
    " - property\n",
    " - installment_plan\n",
    " - housing\n",
    " - telephone\n",
    " - foreign_worker\n",
    " - job\n",
    " \n",
    " ## NA Values\n",
    " - None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3. Balanced / Imbalanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'credit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-f8307f338078>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcredit\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdescribe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'object'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'credit' is not defined"
     ]
    }
   ],
   "source": [
    "credit.describe(include='object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Balanced / Imbalanced target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Identify whether the target column is balanced or imbalanced. Plot the same using a simple table \n",
    "credit['default'].value_counts() / credit.shape[0] * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Convert all columns to numeric\n",
    "\n",
    "## One Hot Encoding the categorical variables\n",
    "<img src=\"https://i.imgur.com/mtimFxh.png\" width=350 height=350>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all columns to numeric\n",
    "credit_numerical = pd.get_dummies(credit, drop_first=True)\n",
    "\n",
    "#credit_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split data in training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'default'\n",
    "\n",
    "input_cols = credit_numerical.drop(target_col, axis=1).columns\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(credit_numerical[input_cols], credit_numerical[target_col], train_size=0.8, random_state=1)\n",
    "\n",
    "credit_numerical.shape,train_x.shape, test_x.shape, train_y.shape, test_y.shape\n",
    "\n",
    "#input_cols is a data frame in python and target_col is a series\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Standardize dataset\n",
    "\n",
    "### Scaling the continuous features using standard scaler\n",
    "\n",
    "$$ scaled \\ X = \\frac{X-\\bar{X}}{\\sigma_x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler().fit(train_x)\n",
    "scaler = MinMaxScaler().fit(train_x)\n",
    "\n",
    "train_x_scaled = pd.DataFrame(scaler.transform(train_x), columns=train_x.columns, index=train_x.index)\n",
    "\n",
    "test_x_scaled = pd.DataFrame(scaler.transform(test_x), columns=test_x.columns, index=test_x.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the data after scaling\n",
    "train_x_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Build Classifier models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_metrics(actual, predicted, classifier_name): \n",
    "    acc = accuracy_score(actual, predicted)\n",
    "    f1 = f1_score(actual, predicted)\n",
    "    tn, fp, fn, tp = confusion_matrix(actual, predicted).ravel() \n",
    "    sensitivity = tp / (tp + fn) \n",
    "    specificity = tn / (tn + fp) \n",
    "    precision = tp / (tp + fp) \n",
    "    recall = tp / (tp + fn) \n",
    "    fpr, tpr, thresholds = roc_curve(actual, predicted, pos_label=1) \n",
    "    auc_value = auc(fpr, tpr)\n",
    "    return {'accuracy': acc, 'f1-score': f1,'classifier': classifier_name, 'sensitivity': sensitivity, 'specificity': specificity, 'AUC': auc_value, 'fpr_values': fpr, 'tpr_values': tpr, 'precision': precision, 'recall': recall}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_cols = ['classifier', 'f1-score', 'sensitivity', 'specificity', 'AUC', 'accuracy', 'precision', 'recall'] \n",
    "df_results = pd.DataFrame(columns=res_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results\n",
    "#test_x_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "\n",
    "classifier_name = 'Logistic Regression'\n",
    "\n",
    "model = LogisticRegression().fit(train_x_scaled, train_y) \n",
    "test_y_pred = model.predict(test_x_scaled)\n",
    "lg_metrics = get_model_metrics(test_y, test_y_pred, classifier_name) \n",
    "print(lg_metrics)\n",
    "if classifier_name not in df_results['classifier'].values: df_results = df_results.append(lg_metrics, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y_pred for checking predicted values by the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y for checking actual values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance Metrics: Confusion matrix, Precision, Recall, and F1 Score\n",
    "\n",
    "<img src=\"https://2.bp.blogspot.com/-EvSXDotTOwc/XMfeOGZ-CVI/AAAAAAAAEiE/oePFfvhfOQM11dgRn9FkPxlegCXbgOF4QCLcBGAs/s1600/confusionMatrxiUpdated.jpg\">\n",
    "\n",
    "<a href=\"https://manisha-sirsat.blogspot.com/2019/04/confusion-matrix.html\">Source</a>\n",
    "\n",
    "<a href=\"https://www.siemens-healthineers.com/en-in/laboratory-diagnostics/assays-by-diseases-conditions/infectious-disease-assays/specificity-matters\">Why specificity matters in Covid19 Test? </a>\n",
    "\n",
    "- True Positive (TP) — model correctly predicts the positive class (prediction and actual both are positive). In the above example, 10 people who have tumors are predicted positively by the model.\n",
    " - True Negative (TN) — model correctly predicts the negative class (prediction and actual both are negative). In the above example, 60 people who don’t have tumors are predicted negatively by the model.\n",
    " - False Positive (FP) — model gives the wrong prediction of the negative class (predicted-positive, actual-negative). In the above example, 22 people are predicted as positive of having a tumor, although they don’t have a tumor. FP is also called a TYPE I error.\n",
    "- False Negative (FN) — model wrongly predicts the positive class (predicted-negative, actual-positive). In the above example, 8 people who have tumors are predicted as negative. FN is also called a TYPE II error.\n",
    "\n",
    "\n",
    "### Which metric to use?\n",
    "\n",
    "The use of metrix depends on the business objective\n",
    " - In case of spam email detection (where spam is positive class) we can to optimize for precision or specificity\n",
    " - In case of detecting fraudulent transactions (fradulent transaction is positive class) we can optimize for sensitivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#metrics.confusion_matrix(test_y, test_y_pred, [2,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_cm( actual, predicted ):   \n",
    "    \n",
    "    cm = metrics.confusion_matrix( actual, predicted, [2,1] )    \n",
    "    \n",
    "    tn = cm[0,0]\n",
    "    fp = cm[0,1]\n",
    "    fn = cm[1,0]\n",
    "    tp = cm[1,1]\n",
    "    \n",
    "    cm = [[tp,fn],[fp,tn]]\n",
    "    \n",
    "    sns.heatmap(cm, annot=True,fmt='.2f', \n",
    "               xticklabels = [\"Good credit\", \"Bad Credit\"] ,\n",
    "               yticklabels = [\"Good credit\", \"Bad Credit\"] )   \n",
    "    plt.ylabel('Actual label')    \n",
    "    plt.xlabel('Predicted label')    \n",
    "    plt.show()\n",
    "\n",
    "draw_cm(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(test_y, test_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Trees\n",
    "\n",
    "classifier_name = 'Decision Tree'\n",
    "model = DecisionTreeClassifier(max_depth=8, random_state=1).fit(train_x_scaled, train_y)\n",
    "test_y_pred = model.predict(test_x_scaled)\n",
    "dt_metrics = get_model_metrics(test_y, test_y_pred, classifier_name) \n",
    "print(dt_metrics)\n",
    "if classifier_name not in df_results['classifier'].values: df_results = df_results.append(dt_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN\n",
    "\n",
    "classifier_name = 'KNN'\n",
    "model = KNeighborsClassifier(n_neighbors=7).fit(train_x_scaled, train_y) \n",
    "test_y_pred = model.predict(test_x_scaled)\n",
    "knn_metrics = get_model_metrics(test_y, test_y_pred, classifier_name) \n",
    "print(knn_metrics)\n",
    "if classifier_name not in df_results['classifier'].values: df_results = df_results.append(knn_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "\n",
    "classifier_name = 'SVM'\n",
    "model = SVC().fit(train_x_scaled, train_y) \n",
    "test_y_pred = model.predict(test_x_scaled)\n",
    "svm_metrics = get_model_metrics(test_y, test_y_pred, classifier_name) \n",
    "print(svm_metrics)\n",
    "if classifier_name not in df_results['classifier'].values: df_results = df_results.append(svm_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier_name = 'Random Forest'\n",
    "RFC = RandomForestClassifier(max_depth=5, random_state=0)\n",
    "\n",
    "model = RFC.fit(train_x_scaled, train_y) \n",
    "test_y_pred = model.predict(test_x_scaled)\n",
    "df_results.drop(['fpr_values', 'tpr_values'], axis=1)\n",
    "rnd_metrics = get_model_metrics(test_y, test_y_pred, classifier_name) \n",
    "print(rnd_metrics)\n",
    "if classifier_name not in df_results['classifier'].values: df_results = df_results.append(rnd_metrics, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_cm(test_y, test_y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8347bce95e25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_y_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test_y' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.confusion_matrix(test_y, test_y_pred, [1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results.drop(['fpr_values', 'tpr_values'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Plot ROC curves\n",
    "\n",
    "<a href=\"https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc\">ROC Curve reference</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lg_metrics['fpr_values'], lg_metrics['tpr_values']) \n",
    "plt.plot(dt_metrics['fpr_values'], dt_metrics['tpr_values']) \n",
    "plt.plot(knn_metrics['fpr_values'], knn_metrics['tpr_values']) \n",
    "plt.plot(svm_metrics['fpr_values'], svm_metrics['tpr_values']) \n",
    "plt.plot(rnd_metrics['fpr_values'], rnd_metrics['tpr_values']) \n",
    "plt.legend(['Logistic Regression; AUC: %.2f' % lg_metrics['AUC'],'Decision Tree; AUC: %.2f' % dt_metrics['AUC'], 'KNN; AUC: %.2f' % knn_metrics['AUC'],'SVM; AUC: %.2f' % svm_metrics['AUC'],'Randon Forest; AUC: %.2f' % rnd_metrics['AUC'],])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Justify your choice of classifier "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For our present case study we need to focus on the optimizing the False Positive and hence the Precision, SVM is better with all the other models on Precision, F1-Score and Accuracy. \n",
    "\n",
    " ### According to business strategy, Precison is the important part which is higher for SVM, so I would suggest to use SVM for modelling in production."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
